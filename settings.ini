[Model]
# Only specify the model version here. The API key is loaded securely from the .env file.
# This keeps your secrets safe and not hardcoded.
model_name = gemini-2.0-flash-001

[Paths]
# The project root is the default base. Use relative paths here.
# Input: Directory for raw data files (Job Descriptions, etc.)
input_dir = input/jd
# Output: Directory for generated artifacts (CVs, Cover Letters, etc.)
export_dir = output/cv
# Directory for session history and long-term memory storage
session_dir = session_storage

# --- User Static Knowledge Base ---
# The root directory containing user profile data
repo_dir = Skill_Repository
# The unstructured document containing full career history and skill details
repo_filename = Master_Resume.docx
# The structured JSON file containing basic info and preferences
profile_filename = user_profile.json

# --- System Instructions & Personas ---
# The TOML file defining agent behaviors, prompts, and persona settings
instruction_file = instruction.toml

[Memory]
# Controls whether long-term conversation history is persisted to disk.
# true = Load/Save history across restarts (Persistent Memory).
# false = Start fresh every time (Ephemeral Session).
enable_long_memory = true

# The maximum number of recent conversation turns (User + Agent pairs) to keep in the context window.
# e.g., 20 turns means the last 40 messages are sent to the LLM.
# Prevents context overflow and manages token usage.
context_window_turns = 20

[Workflow]
# --- Agentic Loop Control ---
# Safety limit for the Validator-Refiner feedback loop.
# If the content isn't approved after this many attempts, the loop forces an exit.
# Prevents infinite loops and excessive token costs.
max_loop_iterations = 3

[Search]
# --- Job Scout Configuration ---
# Default search engine used by the 'find_and_download_jobs_tool'.
# Options: 'linkedin' (Recommended for detail) or 'google' (Broader reach).
default_engine = linkedin

# The maximum number of job results to fetch and process in a single batch run.
# A safety brake to manage API quotas and processing time.
max_results = 5

[RapidAPI]
# --- External API Endpoints & Limits ---
# NOTE: Your RAPIDAPI_KEY must be set in the .env file.

# LinkedIn Job Search API Host
host_linkedin = linkedin-job-search-api.p.rapidapi.com
# Number of results per page requests (API limit may vary).
linkedin_limit = 10
# Hard ceiling for total records to fetch across multiple pages.
linkedin_max_records = 20

# Google Jobs (JSearch) API Host
host_google = jsearch.p.rapidapi.com
# Number of pages to fetch (each page is typically 10 results).
google_max_pages = 1

[Voice]
# --- Multimodal Settings (Speech-to-Text & Text-to-Speech) ---
# Master switch to enable or disable all voice features.
enabled = false

# Engine Selection:
# stt_engine: 'google' (Online, faster) OR 'whisper' (Local, private, higher accuracy)
# tts_engine: 'edge-tts' (High-quality neural voices via Microsoft Edge online service)
stt_engine = google
tts_engine = edge-tts

# Language settings for speech recognition and synthesis.
input_language = en-US
# Voice persona for TTS output (e.g., en-US-AriaNeural, en-AU-NatashaNeural).
output_voice = en-US-AriaNeural

# Playback speed adjustment. e.g., "+0%", "+10%", "-5%".
speaking_rate = +0%

# Local Whisper Model Configuration (Only used if stt_engine = whisper)
# model_size: 'tiny', 'base', 'small', 'medium', 'large-v2' (Larger = more accurate but slower)
# device: 'cpu' (standard) or 'cuda' (requires NVIDIA GPU)
# compute_type: 'int8' (optimized for CPU), 'float16' (optimized for GPU)
whisper_model_size = base.en
whisper_device = cpu
whisper_compute_type = int8

# Voice Scope Control:
# Defines which parts of the system use voice output.
# Options: 'all' (global), 'mock_interview' (only during interviews), or comma-separated list.
# Example: scope = mock_interview, interview_copilot
scope = all

[Personas]
# Names used in the UI and prompts for persona switching.
copilot_name = Joey
interviewer_name = Mary
# Optional: User's name for personalized greetings. Leave blank to use name from user_profile.json.
user_name =